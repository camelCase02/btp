{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.5.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.5.0\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow==2.5.0 scikit-learn optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dummy_npwarn_decorator_factory():\n",
        "  def npwarn_decorator(x):\n",
        "    return x\n",
        "  return npwarn_decorator\n",
        "np._no_nep50_warning = getattr(np, '_no_nep50_warning', dummy_npwarn_decorator_factory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n",
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_mlp_model(input_shape,hidden_layer_one,dropout_one,hidden_layer_two,dropout_two):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(hidden_layer_one, activation='relu',  kernel_regularizer=l2(0.001), input_shape=input_shape))\n",
        "    if dropout_one !=0:\n",
        "        model.add(Dropout(dropout_one))\n",
        "    model.add(Dense(hidden_layer_two, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    if dropout_two !=0:\n",
        "        model.add(Dropout(dropout_two))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    # Compile the model\n",
        "    model.compile(loss='mean_squared_error', optimizer=\"Adam\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_error(trues, predicted):\n",
        "    corr = np.corrcoef(predicted, trues)[0,1]\n",
        "    mae = np.mean(np.abs(predicted - trues))\n",
        "    rae = np.sum(np.abs(predicted - trues)) / np.sum(np.abs(trues - np.mean(trues)))\n",
        "    rmse = np.sqrt(np.mean((predicted - trues)**2))\n",
        "    rrse = np.sqrt(np.sum((predicted - trues)**2) / np.sum((trues - np.mean(trues))**2))\n",
        "    mape = np.mean(np.abs((predicted - trues) / trues)) * 100\n",
        "    r2 = max(0, 1 - np.sum((predicted - trues)**2) / np.sum((trues - np.mean(trues))**2))\n",
        "    # Calculez les autres mesures d'erreur ici\n",
        "    return rmse, corr, mae, rae, rrse, mape, r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "5C0BkZXt65Ez",
        "outputId": "23a1bc40-2ac9-4a90-9040-db4f19ee38d6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import optuna\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "o3bTXF_XcinP",
        "outputId": "f76c02a0-521f-4017-c706-a3cf084c3307"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F0LEKbphcinQ"
      },
      "source": [
        "# We start by loading the pre-processed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "iok0znZ9cinS",
        "outputId": "13141a83-357f-41a0-df1b-e57456394b51"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Inflation</th>\n",
              "      <th>Month</th>\n",
              "      <th>Year</th>\n",
              "      <th>pmi</th>\n",
              "      <th>PartNo</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Sales Price</th>\n",
              "      <th>Total Sales</th>\n",
              "      <th>Swaraj Engines Stock Price</th>\n",
              "      <th>M&amp;M Stock Price</th>\n",
              "      <th>Escorts Kuboto Stock Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.59</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>250</td>\n",
              "      <td>0503BA0290N-RK</td>\n",
              "      <td>ALFA HUB</td>\n",
              "      <td>85</td>\n",
              "      <td>2118.60</td>\n",
              "      <td>59367</td>\n",
              "      <td>1125.0</td>\n",
              "      <td>532.9</td>\n",
              "      <td>630.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.59</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>250</td>\n",
              "      <td>0503BA0290N</td>\n",
              "      <td>Front Wheel Hub</td>\n",
              "      <td>318</td>\n",
              "      <td>3536.35</td>\n",
              "      <td>59367</td>\n",
              "      <td>1125.0</td>\n",
              "      <td>532.9</td>\n",
              "      <td>630.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.59</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>250</td>\n",
              "      <td>0502BA1050N</td>\n",
              "      <td>Alfa Rear Wheel Hub LH</td>\n",
              "      <td>209</td>\n",
              "      <td>1383.36</td>\n",
              "      <td>59367</td>\n",
              "      <td>1125.0</td>\n",
              "      <td>532.9</td>\n",
              "      <td>630.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.59</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>250</td>\n",
              "      <td>0502BA1060N</td>\n",
              "      <td>Alfa Rear Wheel Hub RH</td>\n",
              "      <td>119</td>\n",
              "      <td>4849.50</td>\n",
              "      <td>59367</td>\n",
              "      <td>1125.0</td>\n",
              "      <td>532.9</td>\n",
              "      <td>630.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.59</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>250</td>\n",
              "      <td>0602AAB00260N</td>\n",
              "      <td>Brake Drum ALFA</td>\n",
              "      <td>134</td>\n",
              "      <td>2462.26</td>\n",
              "      <td>59367</td>\n",
              "      <td>1125.0</td>\n",
              "      <td>532.9</td>\n",
              "      <td>630.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Inflation  Month  Year  pmi          PartNo             Description  \\\n",
              "0       7.59      1  2020  250  0503BA0290N-RK                ALFA HUB   \n",
              "1       7.59      1  2020  250     0503BA0290N         Front Wheel Hub   \n",
              "2       7.59      1  2020  250     0502BA1050N  Alfa Rear Wheel Hub LH   \n",
              "3       7.59      1  2020  250     0502BA1060N  Alfa Rear Wheel Hub RH   \n",
              "4       7.59      1  2020  250   0602AAB00260N         Brake Drum ALFA   \n",
              "\n",
              "   Quantity  Sales Price  Total Sales  Swaraj Engines Stock Price  \\\n",
              "0        85      2118.60        59367                      1125.0   \n",
              "1       318      3536.35        59367                      1125.0   \n",
              "2       209      1383.36        59367                      1125.0   \n",
              "3       119      4849.50        59367                      1125.0   \n",
              "4       134      2462.26        59367                      1125.0   \n",
              "\n",
              "   M&M Stock Price  Escorts Kuboto Stock Price  \n",
              "0            532.9                       630.0  \n",
              "1            532.9                       630.0  \n",
              "2            532.9                       630.0  \n",
              "3            532.9                       630.0  \n",
              "4            532.9                       630.0  "
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "order_history_data=pd.read_csv('../data/final_data.csv')\n",
        "order_history_data.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "accsf3FX-psn"
      },
      "source": [
        "# Deep learning model optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "scn8bL42tsdw"
      },
      "outputs": [],
      "source": [
        "X = order_history_data.copy()\n",
        "y = order_history_data['Quantity']\n",
        "\n",
        "X_encoded = pd.get_dummies(X, columns=['Description', 'PartNo'])\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_encoded, y, test_size=0.3, random_state=27)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=27)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9xS2bFBycinX"
      },
      "source": [
        "We're going to use mlp. To start with, we'll create an mlp with minimal parameters to get an idea of performance without model optimization. Then we'll optmize our model using Bayesian optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "WWk8p6_LcinX",
        "outputId": "692b591b-a8c3-4db4-c394-bcb350fd4cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Set:\n",
            "MSE (Mean Squared Error) on the validation set: 9.827682932626185\n",
            "R-squared (Coefficient of Determination) on the validation set: 0.9995434233230256\n",
            "\n",
            "Test Set:\n",
            "MSE (Mean Squared Error) on the test set: 13.485153652621674\n",
            "R-squared (Coefficient of Determination) on the test set: 0.9993998228489208\n"
          ]
        }
      ],
      "source": [
        "\n",
        "best_mlp = MLPRegressor(hidden_layer_sizes=(50), activation='relu', alpha=0.008724528119026307, learning_rate='constant')\n",
        "\n",
        "# Train the model on the training data\n",
        "best_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set with the trained model\n",
        "y_val_pred = best_mlp.predict(X_val)\n",
        "\n",
        "# Evaluate the performance of the model on the validation set\n",
        "mse_val = mean_squared_error(y_val, y_val_pred)\n",
        "r2_val = best_mlp.score(X_val, y_val)\n",
        "\n",
        "# Make predictions on the test set with the trained model\n",
        "y_test_pred = best_mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model on the test set\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "r2_test = best_mlp.score(X_test, y_test)\n",
        "\n",
        "print(\"Validation Set:\")\n",
        "print(\"MSE (Mean Squared Error) on the validation set:\", mse_val)\n",
        "print(\"R-squared (Coefficient of Determination) on the validation set:\", r2_val)\n",
        "\n",
        "print(\"\\nTest Set:\")\n",
        "print(\"MSE (Mean Squared Error) on the test set:\", mse_test)\n",
        "print(\"R-squared (Coefficient of Determination) on the test set:\", r2_test)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "spupqHY9cinY"
      },
      "source": [
        "Using Bayesian optimization to find the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Objective function for Optuna optimization\n",
        "# def objective(trial):\n",
        "#     # Define the hyperparameters to be optimized\n",
        "#     hidden_layer_one = trial.suggest_categorical('hidden_layer_one', [32])\n",
        "#     hidden_layer_two = trial.suggest_categorical('hidden_layer_two', [32])\n",
        "#     dropout_one = trial.suggest_uniform('dropout_one', 0.2, 0.4)\n",
        "#     dropout_two = trial.suggest_uniform('dropout_two', 0.1, 0.3)\n",
        "#     # learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
        "#     batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128,256,512])\n",
        "#     epochs = trial.suggest_categorical('epochs', [200])\n",
        "\n",
        "\n",
        "\n",
        "#     model=get_mlp_model(input_shape=(X_train.shape[1],),hidden_layer_one=hidden_layer_one,dropout_one=dropout_one,hidden_layer_two=hidden_layer_two,dropout_two=dropout_two)\n",
        "\n",
        "\n",
        "#     # Define the ModelCheckpoint callback\n",
        "#     checkpoint_filepath = 'model_checkpoint.h5'\n",
        "#     model_checkpoint = ModelCheckpoint(\n",
        "#         filepath=checkpoint_filepath,\n",
        "#         save_best_only=True,\n",
        "#         monitor='val_loss',\n",
        "#         mode='min',\n",
        "#         verbose=0\n",
        "#     )\n",
        "\n",
        "#     # Train the model on the training data with validation data and checkpoint callback\n",
        "#     history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0\n",
        "#                         , validation_data=(X_val, y_val),\n",
        "#                         callbacks=[model_checkpoint])\n",
        "\n",
        "#     # Load the best weights from the saved checkpoint\n",
        "#     model.load_weights(checkpoint_filepath)\n",
        "\n",
        "#     # Evaluate the performance of the model on the test set\n",
        "#     y_test_pred = model.predict(X_test)\n",
        "\n",
        "#     # Calculate performance metrics\n",
        "#     mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "#     # rmse2, corr2, mae2, rae2, rrse2, mape2, r2_2 = compute_error(y_test.values, y_test_pred.reshape(y_test_pred.shape[0]))\n",
        "\n",
        "#     return mse_test\n",
        "\n",
        "# # Configure Optuna to use the GPU for exhaustive searches\n",
        "# study = optuna.create_study(direction='minimize')\n",
        "# study.optimize(objective, n_trials=65, n_jobs=1)  # Use n_jobs=1 to avoid parallelism problems on GPU\n",
        "\n",
        "# # Show best hyperparameters found\n",
        "# print(\"Best hy    perparameters:\")\n",
        "# print(study.best_params)\n",
        "# print(\"Best MSE:\", study.best_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "# best_params = study.best_params\n",
        "# best_mse = study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(best_params)\n",
        "# print(best_mse)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MFAmNGI7cinY"
      },
      "source": [
        "Using Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "# r2=0\n",
        "\n",
        "# for hidden_layer_one in [25,50,75,100,125,150,175,200,225,350,300,350,400]:\n",
        "#   for hidden_layer_two in [325,50,75,100,125,150,175,200,225,350,300,350,400]:\n",
        "#       for dropout_one in [0,0.1,0.2,0.3,0.4,0.5]:\n",
        "#         for dropout_two in [0,0.1,0.2,0.3,0.4,0.5]:\n",
        "#           # for batch_size in [32,64,128,256]:\n",
        "\n",
        "\n",
        "#             model=get_mlp_model(input_shape=(X_train.shape[1],),hidden_layer_one=hidden_layer_one,dropout_one=dropout_one,hidden_layer_two=hidden_layer_two,dropout_two=dropout_two)\n",
        "\n",
        "#             # Define the ModelCheckpoint callback\n",
        "#             checkpoint_filepath = 'model_checkpoint.h5'\n",
        "#             model_checkpoint = ModelCheckpoint(\n",
        "#                 filepath=checkpoint_filepath,\n",
        "#                 save_best_only=True,\n",
        "#                 monitor='val_loss',\n",
        "#                 mode='min',\n",
        "#                 verbose=0\n",
        "#             )\n",
        "\n",
        "#             # Train the model on the training data with validation data and checkpoint callback\n",
        "#             history = model.fit(X_train, y_train, epochs=300, batch_size=256,\n",
        "#                                 verbose=0, validation_data=(X_val, y_val),\n",
        "#                                 callbacks=[model_checkpoint])\n",
        "\n",
        "#             # Load the best weights from the saved checkpoint\n",
        "#             model.load_weights(checkpoint_filepath)\n",
        "\n",
        "#             # Evaluate the performance of the model on the test set\n",
        "#             y_test_pred = model.predict(X_test)\n",
        "\n",
        "#             # Calculate performance metrics\n",
        "#             mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "#             rmse2, corr2, mae2, rae2, rrse2, mape2, r2_2 = compute_error(y_test.values, y_test_pred.reshape(y_test_pred.shape[0]))\n",
        "\n",
        "#             if r2_2>r2:\n",
        "#               r2=r2_2\n",
        "#               print(\"{},{},{},{}\".format(hidden_layer_one,hidden_layer_two,dropout_one,dropout_two) )\n",
        "#               print(\"RMSE:\", rmse2)\n",
        "#               print(\"Corrélation:\", corr2)\n",
        "#               print(\"MAE:\", mae2)\n",
        "#               print(\"RAE:\", rae2)\n",
        "#               print(\"RRSE:\", rrse2)\n",
        "#               print(\"MAPE:\", mape2)\n",
        "#               print(\"R2:\", r2_2)\n",
        "#               print(\"MSE:\", mse_test)\n",
        "#               print(\"----------------------------------\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0fXRG0VmcinZ"
      },
      "source": [
        "Training model with best hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1l_cOCQyyXH",
        "outputId": "cc03c112-6f37-424a-8b44-1782197d1ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/panda/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 1s - 13ms/step - loss: 4037218.5000 - val_loss: 22566.2461\n",
            "Epoch 2/200\n",
            "57/57 - 0s - 2ms/step - loss: 780795.6250 - val_loss: 39983.3984\n",
            "Epoch 3/200\n",
            "57/57 - 0s - 3ms/step - loss: 335926.0625 - val_loss: 34999.2188\n",
            "Epoch 4/200\n",
            "57/57 - 0s - 2ms/step - loss: 221183.1406 - val_loss: 29573.6191\n",
            "Epoch 5/200\n",
            "57/57 - 0s - 2ms/step - loss: 121937.9062 - val_loss: 25034.7871\n",
            "Epoch 6/200\n",
            "57/57 - 0s - 2ms/step - loss: 56828.1875 - val_loss: 29352.3203\n",
            "Epoch 7/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 3ms/step - loss: 39603.4883 - val_loss: 22121.8496\n",
            "Epoch 8/200\n",
            "57/57 - 0s - 2ms/step - loss: 33783.9648 - val_loss: 22183.2754\n",
            "Epoch 9/200\n",
            "57/57 - 0s - 3ms/step - loss: 30440.8594 - val_loss: 25702.2109\n",
            "Epoch 10/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 2ms/step - loss: 28981.3418 - val_loss: 18755.6680\n",
            "Epoch 11/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 3ms/step - loss: 26919.4023 - val_loss: 17149.8457\n",
            "Epoch 12/200\n",
            "57/57 - 0s - 2ms/step - loss: 25413.9375 - val_loss: 18251.4160\n",
            "Epoch 13/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 3ms/step - loss: 25085.0234 - val_loss: 16703.8281\n",
            "Epoch 14/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 2ms/step - loss: 21761.7891 - val_loss: 15654.8574\n",
            "Epoch 15/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 3ms/step - loss: 22062.2422 - val_loss: 14441.8008\n",
            "Epoch 16/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 3ms/step - loss: 21125.6074 - val_loss: 11729.6074\n",
            "Epoch 17/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 2ms/step - loss: 18935.5898 - val_loss: 10536.4639\n",
            "Epoch 18/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 3ms/step - loss: 18157.4746 - val_loss: 9465.4346\n",
            "Epoch 19/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 3ms/step - loss: 16457.0020 - val_loss: 6545.7485\n",
            "Epoch 20/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 2ms/step - loss: 15835.7617 - val_loss: 5676.3613\n",
            "Epoch 21/200\n",
            "57/57 - 0s - 2ms/step - loss: 14167.4053 - val_loss: 5955.1455\n",
            "Epoch 22/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 2ms/step - loss: 11781.2539 - val_loss: 4274.0493\n",
            "Epoch 23/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 2ms/step - loss: 13073.7881 - val_loss: 2337.3325\n",
            "Epoch 24/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 3ms/step - loss: 11253.7510 - val_loss: 1718.0424\n",
            "Epoch 25/200\n",
            "57/57 - 0s - 2ms/step - loss: 11703.4854 - val_loss: 2603.6455\n",
            "Epoch 26/200\n",
            "57/57 - 0s - 2ms/step - loss: 11738.5449 - val_loss: 2240.3801\n",
            "Epoch 27/200\n",
            "57/57 - 0s - 2ms/step - loss: 10931.4297 - val_loss: 2070.8975\n",
            "Epoch 28/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 2ms/step - loss: 10439.2891 - val_loss: 1090.3081\n",
            "Epoch 29/200\n",
            "57/57 - 0s - 2ms/step - loss: 9892.7637 - val_loss: 1609.3414\n",
            "Epoch 30/200\n",
            "57/57 - 0s - 2ms/step - loss: 10231.6016 - val_loss: 3249.4885\n",
            "Epoch 31/200\n",
            "57/57 - 0s - 2ms/step - loss: 10338.1162 - val_loss: 1670.1498\n",
            "Epoch 32/200\n",
            "57/57 - 0s - 2ms/step - loss: 9904.6133 - val_loss: 1589.4706\n",
            "Epoch 33/200\n",
            "57/57 - 0s - 2ms/step - loss: 9487.2852 - val_loss: 1277.5625\n",
            "Epoch 34/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 - 0s - 2ms/step - loss: 9756.9189 - val_loss: 653.1475\n",
            "Epoch 35/200\n",
            "57/57 - 0s - 2ms/step - loss: 9585.3730 - val_loss: 2426.2754\n",
            "Epoch 36/200\n",
            "57/57 - 0s - 2ms/step - loss: 8958.3242 - val_loss: 1737.5212\n",
            "Epoch 37/200\n",
            "57/57 - 0s - 2ms/step - loss: 8897.8994 - val_loss: 1614.1183\n",
            "Epoch 38/200\n",
            "57/57 - 0s - 3ms/step - loss: 8711.7490 - val_loss: 2386.8318\n",
            "Epoch 39/200\n",
            "57/57 - 0s - 2ms/step - loss: 8645.0059 - val_loss: 2409.7065\n",
            "Epoch 40/200\n",
            "57/57 - 0s - 2ms/step - loss: 9577.5586 - val_loss: 2586.5203\n",
            "Epoch 41/200\n",
            "57/57 - 0s - 2ms/step - loss: 9256.9512 - val_loss: 1873.6342\n",
            "Epoch 42/200\n",
            "57/57 - 0s - 3ms/step - loss: 9005.3906 - val_loss: 1379.8479\n",
            "Epoch 43/200\n",
            "57/57 - 0s - 3ms/step - loss: 9312.2949 - val_loss: 892.0172\n",
            "Epoch 44/200\n",
            "57/57 - 0s - 2ms/step - loss: 8794.7607 - val_loss: 1818.4382\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step\n",
            "RMSE: 25.863664111189173\n",
            "Corrélation: 0.9957744442299397\n",
            "MAE: 20.381084843685752\n",
            "RAE: 0.16525361307616906\n",
            "RRSE: 0.17254478222739958\n",
            "MAPE: 17.891244323058846\n",
            "R2: 0.9702282981260992\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "# best parameters\n",
        "\n",
        "# hidden_layer_one=best_params['hidden_layer_one']\n",
        "# hidden_layer_two=best_params['hidden_layer_two']\n",
        "# dropout_one=best_params['dropout_one']  \n",
        "# dropout_two=best_params['dropout_two']\n",
        "\n",
        "# epochs=best_params['epochs']\n",
        "# batch_size=best_params['batch_size']\n",
        "\n",
        "\n",
        "hidden_layer_one=32\n",
        "hidden_layer_two=32\n",
        "dropout_one=0.20717484583420542\n",
        "dropout_two=0.11283000231601609\n",
        "\n",
        "epochs=200\n",
        "batch_size=128\n",
        "\n",
        "\n",
        "model=get_mlp_model(input_shape=(X_train.shape[1],),hidden_layer_one=hidden_layer_one,dropout_one=dropout_one,hidden_layer_two=hidden_layer_two,dropout_two=dropout_two)\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_filepath = '../checkpoints/bayesian_final_model_checkpoint.h5'\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "filepath=checkpoint_filepath,\n",
        "save_best_only=True,\n",
        "monitor='val_loss',\n",
        "mode='min',\n",
        "verbose=0\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model on the training data with validation data and checkpoint callback\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "            verbose=2, validation_data=(X_val, y_val),\n",
        "            callbacks=[model_checkpoint, early_stopping])\n",
        "\n",
        "# Load the best weights from the saved checkpoint\n",
        "model.load_weights(checkpoint_filepath)\n",
        "\n",
        "# Evaluate the performance of the model on the test set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "rmse2, corr2, mae2, rae2, rrse2, mape2, r2_2 = compute_error(y_test.values, y_test_pred.reshape(y_test_pred.shape[0]))\n",
        "\n",
        "print(\"RMSE:\", rmse2)\n",
        "print(\"Corrélation:\", corr2)\n",
        "print(\"MAE:\", mae2)\n",
        "print(\"RAE:\", rae2)\n",
        "print(\"RRSE:\", rrse2)\n",
        "print(\"MAPE:\", mape2)\n",
        "print(\"R2:\", r2_2)\n",
        "print(\"----------------------------------\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AN-8AO2Ecina"
      },
      "source": [
        "Save the weights of the best model for later loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "HUAXH6qwi2By"
      },
      "outputs": [],
      "source": [
        "# Save the best model in checkpoint only if it is better\n",
        "model.save_weights('../checkpoints/bayesian_final.weights.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
